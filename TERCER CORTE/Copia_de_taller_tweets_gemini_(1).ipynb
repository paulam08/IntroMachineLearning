{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b357f7b0",
      "metadata": {
        "id": "b357f7b0"
      },
      "source": [
        "# Taller: An√°lisis de Tweets con Gemini API\n",
        "Autor: _(Paula Maldonado)_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe82eab",
      "metadata": {
        "id": "2fe82eab"
      },
      "source": [
        "## Objetivos\n",
        "1. Configurar la API de Google¬†Generative¬†AI (Gemini).\n",
        "2. Limpiar y pre‚Äëprocesar un corpus de tweets pol√≠ticos.\n",
        "3. Clasificar sentimiento con Gemini.\n",
        "4. Extraer temas con LDA y nombrarlos con Gemini.\n",
        "5. Segmentar usuarios y generar una micro‚Äëcampa√±a basada en insights.\n",
        "\n",
        "**Dataset**: `tweets_partidos.csv` (columnas: `cuenta`, `partido`, `timestamp`, `tweet`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/javierherrera1996/IntroMarketingAnalytics/raw/refs/heads/main/SegundoCorte/tweets_politica_kaggle.csv.zip"
      ],
      "metadata": {
        "id": "e8udN5R9O0km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e08fe5-ac70-4d5d-8b3f-4483b0d250ae"
      },
      "id": "e8udN5R9O0km",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-26 18:49:42--  https://github.com/javierherrera1996/IntroMarketingAnalytics/raw/refs/heads/main/SegundoCorte/tweets_politica_kaggle.csv.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/javierherrera1996/IntroMarketingAnalytics/refs/heads/main/SegundoCorte/tweets_politica_kaggle.csv.zip [following]\n",
            "--2025-05-26 18:49:42--  https://raw.githubusercontent.com/javierherrera1996/IntroMarketingAnalytics/refs/heads/main/SegundoCorte/tweets_politica_kaggle.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18276075 (17M) [application/zip]\n",
            "Saving to: ‚Äòtweets_politica_kaggle.csv.zip‚Äô\n",
            "\n",
            "tweets_politica_kag 100%[===================>]  17.43M  92.6MB/s    in 0.2s    \n",
            "\n",
            "2025-05-26 18:49:43 (92.6 MB/s) - ‚Äòtweets_politica_kaggle.csv.zip‚Äô saved [18276075/18276075]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tweets_politica_kaggle.csv.zip"
      ],
      "metadata": {
        "id": "PJC93YJdO1vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2e5c0a-ded9-4b66-e4b3-289a06a6e648"
      },
      "id": "PJC93YJdO1vG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tweets_politica_kaggle.csv.zip\n",
            "  inflating: tweets_politica_kaggle.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('tweets_politica_kaggle.csv',delimiter=\",\",on_bad_lines='skip')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "LXleE-CzQZ0m",
        "outputId": "86a41859-8add-4261-8487-090c26e5abb6"
      },
      "id": "LXleE-CzQZ0m",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   cuenta\\tpartido\\ttimestamp\\ttweet\n",
              "0  a34133350b0605cb24081843f63176ca\\tpsoe\\t136397...\n",
              "1  a34133350b0605cb24081843f63176ca\\tpsoe\\t136406...\n",
              "2  a34133350b0605cb24081843f63176ca\\tpsoe\\t136411...\n",
              "3  a34133350b0605cb24081843f63176ca\\tpsoe\\t136415...\n",
              "4  a34133350b0605cb24081843f63176ca\\tpsoe\\t136415..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cfeee06-cc82-4fea-bcf5-d8fd2c076b97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cuenta\\tpartido\\ttimestamp\\ttweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136397...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136406...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136411...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136415...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136415...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cfeee06-cc82-4fea-bcf5-d8fd2c076b97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cfeee06-cc82-4fea-bcf5-d8fd2c076b97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cfeee06-cc82-4fea-bcf5-d8fd2c076b97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68337c45-5a21-4a7f-bdaa-83fc972b4cef\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68337c45-5a21-4a7f-bdaa-83fc972b4cef')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68337c45-5a21-4a7f-bdaa-83fc972b4cef button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 81097,\n  \"fields\": [\n    {\n      \"column\": \"cuenta\\tpartido\\ttimestamp\\ttweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 80991,\n        \"samples\": [\n          \"1e826d8471835f7feb02f8028b736ebb\\tpp\\t1610190565.0\\tEnero de 2018\\ud83d\\udc49\\ud83c\\udffc S\\u00e1nchez denunciaba la gesti\\u00f3n de una nevada incomparable a la que ahora deja Filomena en Madrid.Enero de 2021\\ud83d\\udc49\\ud83c\\udffc S\\u00e1nchez no est\\u00e1 ni se le espera.\\ud83d\\udd34\\u00bfAhora no exige responsabilidades?\\ud83d\\udd34\\u00bfYa no pide explicaciones?\\ud83d\\udd34\\u00bfD\\u00f3nde est\\u00e1 escondido con la que est\\u00e1 cayendo? https://t.co/akRw8ljDnw\",\n          \"647360a97c0671126705c66ebdeacd33\\tpodemos\\t1644342435.0\\t\\\"\\ud83c\\udfa5 \\\"\\\"Tenemos un proyecto que pasa por garantizar todos los derechos de los ciudadanos y las ciudadanas de Castilla y Le\\u00f3n. Que Unidas Podemos est\\u00e9 fuerte es la mejor garant\\u00eda de que hay vidas dignas para los castellanos y los leoneses\\\"\\\".@IreneMontero en Valladolid \\ud83d\\udc47 https://t.co/qZk8FGFDXA\\\"\",\n          \"3a97e533064700b11a5679036006ab12\\tpsoe\\t1627465295.0\\t#QuoVadisEuropa @uimp El debate sobre la promoci\\u00f3n de valores y democracia desde la UE al resto del mundo.https://t.co/mwU5jTxsCF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bb91e5a2",
      "metadata": {
        "id": "bb91e5a2"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai nltk seaborn wordcloud scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906704c8",
      "metadata": {
        "id": "906704c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd15766",
      "metadata": {
        "id": "6dd15766"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e18f9a",
      "metadata": {
        "id": "b4e18f9a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4a8217c6",
      "metadata": {
        "id": "4a8217c6"
      },
      "source": [
        "### üîç Preguntas ‚Äì Secci√≥n‚ÄØ1 (Exploraci√≥n)\n",
        "1. **¬øCu√°ntos tweets hay en total?**  \n",
        "2. **¬øQu√© partidos aparecen y cu√°ntos tweets aporta cada uno?**  \n",
        "3. **¬øCu√°l es el rango de fechas cubierto por los tweets?**  \n",
        "4. **¬øQu√© partido genera m√°s conversaci√≥n y por qu√© crees que ocurre?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file, specifying the tab delimiter\n",
        "df = pd.read_csv('tweets_politica_kaggle.csv', delimiter='\\t', on_bad_lines='skip')\n",
        "\n",
        "# Now, accessing the 'partido' column should work\n",
        "partidos_counts = df['partido'].value_counts()\n",
        "print(\"\\nTweets por partido:\")\n",
        "print(partidos_counts)\n",
        "\n",
        "# Continue with the rest of the original code for calculations and printing\n",
        "total_tweets = len(df)\n",
        "print(f\"Total de tweets: {total_tweets}\")\n",
        "\n",
        "# Convert the 'timestamp' column to datetime objects\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "fecha_inicio = df['timestamp'].min()\n",
        "fecha_fin = df['timestamp'].max()\n",
        "print(f\"\\nRango de fechas: Desde {fecha_inicio} hasta {fecha_fin}\")\n",
        "\n",
        "# Determine the party with the most tweets\n",
        "partido_mas_conversacion = partidos_counts.idxmax()\n",
        "print(f\"\\nEl partido que genera m√°s conversaci√≥n es: {partido_mas_conversacion}\")\n",
        "print(\"Posibles razones (cualitativas, no derivadas del c√≥digo):\")\n",
        "print(\"- Eventos pol√≠ticos importantes que involucraron a ese partido.\")\n",
        "print(\"- Mayor n√∫mero de seguidores activos en Twitter.\")\n",
        "print(\"- Estrategias de comunicaci√≥n digital m√°s efectivas por parte del partido.\")\n",
        "print(\"- Controversias o noticias relevantes relacionadas con el partido.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO_frfMG7wXq",
        "outputId": "30ddece0-1ff7-407d-999d-e3135637e51b"
      },
      "id": "FO_frfMG7wXq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tweets por partido:\n",
            "partido\n",
            "psoe          42818\n",
            "vox           38277\n",
            "pp            35059\n",
            "podemos       34442\n",
            "ciudadanos    30908\n",
            "Name: count, dtype: int64\n",
            "Total de tweets: 181504\n",
            "\n",
            "Rango de fechas: Desde 1970-01-01 00:00:01.363973492 hasta 1970-01-01 00:00:01.651224962\n",
            "\n",
            "El partido que genera m√°s conversaci√≥n es: psoe\n",
            "Posibles razones (cualitativas, no derivadas del c√≥digo):\n",
            "- Eventos pol√≠ticos importantes que involucraron a ese partido.\n",
            "- Mayor n√∫mero de seguidores activos en Twitter.\n",
            "- Estrategias de comunicaci√≥n digital m√°s efectivas por parte del partido.\n",
            "- Controversias o noticias relevantes relacionadas con el partido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c06a3675",
      "metadata": {
        "id": "c06a3675"
      },
      "source": [
        "### üßπ Preguntas ‚Äì Secci√≥n‚ÄØ2 (Limpieza)\n",
        "5. Explica **por qu√© es importante limpiar y normalizar el texto**.  \n",
        "6. Enumera **tres tipos de ‚Äúruido‚Äù** que removes y da un ejemplo de cada uno."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es fundamental limpiar y normalizar el texto por varias razones, especialmente cuando se trabaja con datos como tweets. Los textos sin procesar suelen contener elementos que no aportan informaci√≥n √∫til para el an√°lisis y pueden incluso distorsionar los resultados. Al limpiar y normalizar, nos aseguramos de que el texto est√© en un formato consistente y relevante, lo que mejora la precisi√≥n y efectividad de las tareas posteriores como el an√°lisis de sentimiento, la extracci√≥n de temas o la segmentaci√≥n.\n",
        "\n",
        "Tres tipos de ‚Äúruido‚Äù que se suelen eliminar son:\n",
        "\n",
        "1.  **Caracteres especiales y signos de puntuaci√≥n:** Estos elementos a menudo no tienen un significado ling√º√≠stico directo en el contexto de un an√°lisis de contenido y pueden introducir ruido.\n",
        "    *   **Ejemplo:** Eliminar `!` , `?` , `@` , `#` , `,` , `.` de un tweet como `\"¬°Hola @usuario! Este es un tweet #interesante...\"` lo dejar√≠a como `\"Hola usuario Este es un tweet interesante\"`.\n",
        "\n",
        "2.  **URLs y menciones de usuario:** Las direcciones web y los nombres de usuario (`@`) son espec√≠ficos de la plataforma (Twitter en este caso) y generalmente no contribuyen al contenido sem√°ntico del tweet.\n",
        "    *   **Ejemplo:** Eliminar `https://t.co/abcdef` y `@usuario` de `\"Mira este art√≠culo: https://t.co/abcdef v√≠a @usuario\"` lo dejar√≠a como `\"Mira este art√≠culo: v√≠a\"`.\n",
        "\n",
        "3.  **Stop words (palabras vac√≠as):** Son palabras muy comunes en un idioma (como \"el\", \"la\", \"y\", \"un\", \"una\") que no suelen aportar mucho significado distintivo al texto, especialmente para tareas como la identificaci√≥n de temas.\n",
        "    *   **Ejemplo:** Eliminar \"el\", \"y\", \"la\" de `\"El perro y la casa son grandes\"` lo dejar√≠a como `\"perro casa grandes\"`.\n",
        "    *   **Ejemplo:** Eliminar `!` , `?` , `@` , `#` , `,` , `.` de un tweet como `\"¬°Hola @usuario! Este es un tweet #interesante...\"` lo dejar√≠a como `\"Hola usuario Este es un tweet interesante\"`."
      ],
      "metadata": {
        "id": "8AekQFqw8Zpt"
      },
      "id": "8AekQFqw8Zpt"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vG9jACNQ8ZWd"
      },
      "id": "vG9jACNQ8ZWd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a2bdb175",
      "metadata": {
        "id": "a2bdb175"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Configure the API key (assuming you have set the GOOGLE_API_KEY environment variable)\n",
        "# Replace with your actual API key if not using environment variable\n",
        "# genai.configure(api_key='YOUR_API_KEY')\n",
        "\n",
        "# Define and initialize the model_fast variable\n",
        "# Using a fast model suitable for classification tasks\n",
        "model_fast = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "\n",
        "# Now, define the classify_sentiment function\n",
        "def classify_sentiment(text, model=model_fast):\n",
        "    prompt = (f\"Clasifica el sentimiento del siguiente tweet como 'positivo', \"\n",
        "              f\"'neutral' o 'negativo'. Solo responde con una palabra.\\n\\nTweet:\\n{text}\")\n",
        "    return model.generate_content(prompt).text.strip().lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bfbc892",
      "metadata": {
        "id": "0bfbc892"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "93d108b4",
      "metadata": {
        "id": "93d108b4"
      },
      "source": [
        "### üòä Preguntas ‚Äì Secci√≥n‚ÄØ3 (Sentimiento)\n",
        "7. Presenta la **distribuci√≥n global** de sentimientos y comenta.  \n",
        "8. **¬øQu√© partido tiene la mayor proporci√≥n de tweets positivos y negativos?**  \n",
        "9. Elige un **pico de sentimiento negativo** y analiza el contexto con un tweet ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d542876c",
      "metadata": {
        "id": "d542876c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cecdef9-2947-4785-a98c-dd1b3029cfd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La columna 'sentimiento' no se encuentra en el DataFrame. Por favor, aseg√∫rate de haber ejecutado la clasificaci√≥n de sentimiento previamente.\n"
          ]
        }
      ],
      "source": [
        "# prompt: Presenta la distribuci√≥n global de sentimientos y comenta.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' now has a 'sentimiento' column from the previous step\n",
        "if 'sentimiento' in df.columns:\n",
        "    # Get the distribution of sentiments\n",
        "    sentiment_counts = df['sentimiento'].value_counts(normalize=True) * 100\n",
        "\n",
        "    # Print the distribution\n",
        "    print(\"\\nDistribuci√≥n Global de Sentimientos:\")\n",
        "    print(sentiment_counts)\n",
        "\n",
        "    # Plot the distribution\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)\n",
        "    plt.title('Distribuci√≥n Global de Sentimientos en Tweets')\n",
        "    plt.xlabel('Sentimiento')\n",
        "    plt.ylabel('Porcentaje')\n",
        "    plt.show()\n",
        "\n",
        "    # Comment on the distribution\n",
        "    print(\"\\nComentario sobre la distribuci√≥n de sentimientos:\")\n",
        "    print(\"Observamos la proporci√≥n de tweets clasificados como positivo, neutral y negativo a nivel global.\")\n",
        "    print(\"Este gr√°fico de barras muestra visualmente qu√© sentimiento predomina en el conjunto de datos total.\")\n",
        "    print(\"Podemos inferir, por ejemplo, si hay una tendencia general m√°s positiva, negativa o neutral en la conversaci√≥n pol√≠tica analizada.\")\n",
        "    print(\"Dependiendo de los resultados, esto podr√≠a indicar el clima general de opini√≥n sobre los temas o actores pol√≠ticos representados en los tweets.\")\n",
        "else:\n",
        "    # This block is executed if the 'sentimiento' column is not found\n",
        "    print(\"La columna 'sentimiento' no se encuentra en el DataFrame. Por favor, aseg√∫rate de haber ejecutado la clasificaci√≥n de sentimiento previamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "70882b31",
      "metadata": {
        "id": "70882b31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0fc390-e3e7-4297-f1ec-2127266f6598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Las columnas 'sentimiento' y/o 'partido' no se encuentran en el DataFrame. Por favor, aseg√∫rate de haber ejecutado la clasificaci√≥n de sentimiento y de que la columna 'partido' est√© presente.\n"
          ]
        }
      ],
      "source": [
        "# prompt: Las columnas 'sentimiento' y/o 'partido' no se encuentran en el DataFrame. Por favor, aseg√∫rate de haber ejecutado la clasificaci√≥n de sentimiento y de que la columna 'partido' est√© presente.\n",
        "\n",
        "# Check if both 'sentimiento' and 'partido' columns exist before proceeding\n",
        "if 'sentimiento' in df.columns and 'partido' in df.columns:\n",
        "    # Calculate the proportion of positive and negative tweets per party\n",
        "    sentiment_party = df.groupby('partido')['sentimiento'].value_counts(normalize=True).unstack()\n",
        "\n",
        "    # Identify the party with the highest proportion of positive tweets\n",
        "    if 'positivo' in sentiment_party.columns:\n",
        "        most_positive_party = sentiment_party['positivo'].idxmax()\n",
        "        print(f\"\\nPartido con la mayor proporci√≥n de tweets positivos: {most_positive_party}\")\n",
        "        print(f\"Proporci√≥n de tweets positivos para {most_positive_party}: {sentiment_party.loc[most_positive_party, 'positivo']:.2%}\")\n",
        "    else:\n",
        "        print(\"\\nNo hay tweets clasificados como 'positivo' en el DataFrame.\")\n",
        "\n",
        "    # Identify the party with the highest proportion of negative tweets\n",
        "    if 'negativo' in sentiment_party.columns:\n",
        "        most_negative_party = sentiment_party['negativo'].idxmax()\n",
        "        print(f\"Partido con la mayor proporci√≥n de tweets negativos: {most_negative_party}\")\n",
        "        print(f\"Proporci√≥n de tweets negativos para {most_negative_party}: {sentiment_party.loc[most_negative_party, 'negativo']:.2%}\")\n",
        "    else:\n",
        "         print(\"\\nNo hay tweets clasificados como 'negativo' en el DataFrame.\")\n",
        "\n",
        "else:\n",
        "    # This block is executed if either 'sentimiento' or 'partido' column is not found\n",
        "    print(\"Las columnas 'sentimiento' y/o 'partido' no se encuentran en el DataFrame. Por favor, aseg√∫rate de haber ejecutado la clasificaci√≥n de sentimiento y de que la columna 'partido' est√© presente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Configure the API key (assuming you have set the GOOGLE_API_KEY environment variable)\n",
        "# Replace with your actual API key if not using environment variable\n",
        "genai.configure(api_key='YOUR_API_KEY') # <-- Uncomment this line and add your API key\n",
        "\n",
        "# Define and initialize the model_fast variable\n",
        "# Using a fast model suitable for classification tasks\n",
        "model_fast = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "\n",
        "# Now, define the classify_sentiment function\n",
        "def classify_sentiment(text, model=model_fast):\n",
        "    prompt = (f\"Clasifica el sentimiento del siguiente tweet como 'positivo', \"\n",
        "              f\"'neutral' o 'negativo'. Solo responde con una palabra.\\n\\nTweet:\\n{text}\")\n",
        "    return model.generate_content(prompt).text.strip().lower()"
      ],
      "metadata": {
        "id": "5QieZBZP9pE4"
      },
      "id": "5QieZBZP9pE4",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "38ebd1db",
      "metadata": {
        "id": "38ebd1db"
      },
      "source": [
        "### üóÇÔ∏è Preguntas ‚Äì Secci√≥n‚ÄØ4 (Temas)\n",
        "10. Lista los **nombres de los temas** generados. ¬øAlguno es inesperado?  \n",
        "11. Con un heatmap partido‚ÄØ√ó‚ÄØtema, indica *qu√© tema es ‚Äúpropiedad‚Äù* de cada partido.  \n",
        "12. Para tu partido elegido, da **dos insights accionables** basados en su tema dominante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c270aaef",
      "metadata": {
        "id": "c270aaef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8741ea-b999-4748-9c1e-ee1e54d33d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombres de los temas generados:\n",
            "Tema 1: Educaci√≥n y Juventud\n",
            "Tema 2: Econom√≠a y Empleo\n",
            "Tema 3: Salud y Bienestar\n",
            "Tema 4: Seguridad y Orden P√∫blico\n",
            "Tema 5: Pol√≠tica Exterior y Relaciones Internacionales\n",
            "\n",
            "Comentario sobre los nombres de los temas:\n",
            "Analiza la lista de nombres de temas. ¬øHay alg√∫n tema que no esperabas encontrar?\n",
            "Considera el contexto pol√≠tico y social del pa√≠s al que pertenecen los tweets para evaluar si los temas identificados son coherentes o si hay sorpresas.\n",
            "Por ejemplo, un tema inesperado podr√≠a ser uno muy espec√≠fico o uno que no se asocia com√∫nmente con el debate pol√≠tico.\n",
            "Las columnas 'partido' y/o 'topic' no se encuentran en el DataFrame. Aseg√∫rate de haber realizado el modelado de temas (LDA) y haber asignado un tema dominante a cada tweet.\n",
            "El partido 'Partido Ejemplo' no se encontr√≥ en la columna 'partido' o las columnas 'partido'/'topic' no est√°n disponibles.\n"
          ]
        }
      ],
      "source": [
        "# prompt: Lista los nombres de los temas generados. ¬øAlguno es inesperado?\n",
        "# Con un heatmap partido‚ÄØ√ó‚ÄØtema, indica qu√© tema es ‚Äúpropiedad‚Äù de cada partido.\n",
        "# Para tu partido elegido, da dos insights accionables basados en su tema dominante.\n",
        "\n",
        "# Assuming 'topic_names' is a list containing the names of the generated topics\n",
        "# This list should be populated from the previous LDA topic modeling step.\n",
        "# Example placeholder:\n",
        "topic_names = [\"Educaci√≥n y Juventud\", \"Econom√≠a y Empleo\", \"Salud y Bienestar\", \"Seguridad y Orden P√∫blico\", \"Pol√≠tica Exterior y Relaciones Internacionales\"] # Replace with your actual topic names\n",
        "\n",
        "print(\"Nombres de los temas generados:\")\n",
        "for i, topic_name in enumerate(topic_names):\n",
        "    print(f\"Tema {i+1}: {topic_name}\")\n",
        "\n",
        "print(\"\\nComentario sobre los nombres de los temas:\")\n",
        "print(\"Analiza la lista de nombres de temas. ¬øHay alg√∫n tema que no esperabas encontrar?\")\n",
        "print(\"Considera el contexto pol√≠tico y social del pa√≠s al que pertenecen los tweets para evaluar si los temas identificados son coherentes o si hay sorpresas.\")\n",
        "print(\"Por ejemplo, un tema inesperado podr√≠a ser uno muy espec√≠fico o uno que no se asocia com√∫nmente con el debate pol√≠tico.\")\n",
        "\n",
        "# Assuming 'df' has a 'partido' column and 'topic' column (where 'topic' is the dominant topic index for each tweet)\n",
        "# This 'topic' column should be added after the LDA topic modeling step.\n",
        "# Create a cross-tabulation of party and dominant topic\n",
        "if 'partido' in df.columns and 'topic' in df.columns:\n",
        "    party_topic_counts = pd.crosstab(df['partido'], df['topic'])\n",
        "\n",
        "    # Normalize the counts to get proportions per party\n",
        "    party_topic_proportions = party_topic_counts.apply(lambda x: x / x.sum(), axis=1)\n",
        "\n",
        "    # Map topic indices to topic names for better readability\n",
        "    party_topic_proportions.columns = topic_names\n",
        "\n",
        "    # Plot the heatmap\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(party_topic_proportions, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
        "    plt.title('Proporci√≥n de Tweets por Tema y Partido')\n",
        "    plt.xlabel('Tema')\n",
        "    plt.ylabel('Partido')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nInterpretaci√≥n del Heatmap:\")\n",
        "    print(\"El heatmap muestra la proporci√≥n de tweets de cada partido que se clasifican dentro de cada tema.\")\n",
        "    print(\"Los valores m√°s altos (colores m√°s oscuros) indican que un tema es m√°s 'propiedad' o m√°s frecuentemente discutido por un partido en particular.\")\n",
        "    print(\"Esto ayuda a identificar qu√© temas son prioritarios para cada plataforma pol√≠tica.\")\n",
        "\n",
        "else:\n",
        "    print(\"Las columnas 'partido' y/o 'topic' no se encuentran en el DataFrame. Aseg√∫rate de haber realizado el modelado de temas (LDA) y haber asignado un tema dominante a cada tweet.\")\n",
        "\n",
        "\n",
        "# --- Insight accionable para un partido elegido ---\n",
        "\n",
        "# Choose a party to analyze\n",
        "# Replace 'Partido Ejemplo' with the actual name of a party from your dataset\n",
        "chosen_party = 'Partido Ejemplo' #@param {type:\"string\"}\n",
        "\n",
        "if 'partido' in df.columns and 'topic' in df.columns and chosen_party in df['partido'].unique():\n",
        "    # Find the dominant topic for the chosen party\n",
        "    if chosen_party in party_topic_proportions.index:\n",
        "        dominant_topic_index = party_topic_proportions.loc[chosen_party].idxmax()\n",
        "        dominant_topic_name = dominant_topic_index # It's already the name due to re-indexing\n",
        "\n",
        "        print(f\"\\nAn√°lisis para el partido: {chosen_party}\")\n",
        "        print(f\"Tema dominante: {dominant_topic_name}\")\n",
        "\n",
        "        print(\"\\nDos insights accionables basados en el tema dominante:\")\n",
        "        # Insight 1: Focus on the dominant theme in communication\n",
        "        print(f\"1. Aumentar la comunicaci√≥n y las propuestas relacionadas con '{dominant_topic_name}'.\")\n",
        "        print(f\"   Dado que este tema resuena m√°s con la audiencia del partido o es un √°rea de fortaleza, enfocarse en √©l puede mejorar el engagement y la percepci√≥n p√∫blica.\")\n",
        "        print(f\"   Acci√≥n: Crear m√°s contenido (tweets, videos, comunicados) que aborde espec√≠ficamente asuntos de '{dominant_topic_name}', destacando las soluciones y logros del partido en esta √°rea.\")\n",
        "\n",
        "        # Insight 2: Identify sub-topics or specific issues within the dominant theme\n",
        "        # This would require drilling down into the tweets related to the dominant topic for the chosen party\n",
        "        # For this example, we'll provide a general insight\n",
        "        print(f\"2. Analizar sub-temas o preocupaciones espec√≠ficas dentro de '{dominant_topic_name}' que generen mayor interacci√≥n.\")\n",
        "        print(f\"   Dentro de un tema amplio como '{dominant_topic_name}', puede haber aspectos particulares que interesen m√°s a los seguidores o generen m√°s debate.\")\n",
        "        print(f\"   Acci√≥n: Examinar los tweets de '{chosen_party}' clasificados en '{dominant_topic_name}' para identificar palabras clave o frases recurrentes que indiquen sub-temas espec√≠ficos. Luego, dise√±ar campa√±as de comunicaci√≥n que aborden directamente estas inquietudes particulares.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"El partido '{chosen_party}' no se encontr√≥ en los datos de proporciones de temas.\")\n",
        "\n",
        "else:\n",
        "    print(f\"El partido '{chosen_party}' no se encontr√≥ en la columna 'partido' o las columnas 'partido'/'topic' no est√°n disponibles.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d2fe739",
      "metadata": {
        "id": "0d2fe739"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c2d37f48",
      "metadata": {
        "id": "c2d37f48"
      },
      "source": [
        "### üë• Preguntas ‚Äì Secci√≥n‚ÄØ5 (Segmentaci√≥n)\n",
        "13. Describe cada **cluster** en una frase (actividad y tono).  \n",
        "14. **¬øQu√© segmento priorizar√≠as** para viralizar un mensaje y por qu√©?  \n",
        "15. Prop√≥n **una acci√≥n de engagement** distinta para cada segmento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b52da84a",
      "metadata": {
        "id": "b52da84a"
      },
      "outputs": [],
      "source": [
        "def generar_copy(partido, topic, tono='inspirador'):\n",
        "    prompt = (f\"Act√∫a como community manager del partido {partido}. \"\n",
        "              f\"Crea un tweet de m√°x. 250 caracteres sobre el tema '{topic}'. \"\n",
        "              f\"Tono {tono}. No incluyas hashtags ni menciones.\")\n",
        "    return model.generate_content(prompt).text.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75a38277",
      "metadata": {
        "id": "75a38277"
      },
      "source": [
        "### üìù Preguntas ‚Äì Secci√≥n‚ÄØ6 (Micro‚Äëcampa√±a)\n",
        "16. Presenta tus **tres tweets** generados.  \n",
        "17. Justifica:  \n",
        "   a) **Tema** elegido.  \n",
        "   b) **Tono** y **horario** √≥ptimos.  \n",
        "18. Define un **KPI de √©xito** y la meta para la campa√±a."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    # Ensure the model object is available within the function\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    # Ensure the model object is available within the function\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "hxQdxszy-DdK",
        "outputId": "322a9544-1aba-4023-d471-d5c200161486"
      },
      "id": "hxQdxszy-DdK",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-104-b47d7eee3afb>, line 48)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-104-b47d7eee3afb>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    Generates text content using the provided generative model and prompt.\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2565b39a",
      "metadata": {
        "id": "2565b39a"
      },
      "source": [
        "## Pr√≥ximos pasos\n",
        "1. Analiza la hora de publicaci√≥n (`df['fecha'].dt.hour`) para programar los tweets.\n",
        "2. Escribe un memo (<400 palabras) justificando la micro‚Äëcampa√±a usando los insights de sentimiento, temas y segmentos.\n",
        "3. Exporta notebook ejecutado y memo para entrega."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Analiza la hora de publicaci√≥n (df['fecha'].dt.hour) para programar los tweets.\n",
        "# Escribe un memo (<400 palabras) justificando la micro‚Äëcampa√±a usando los insights de sentimiento, temas y segmentos.\n",
        "# Exporta notebook ejecutado y memo para entrega.\n",
        "\n",
        "# Analyze publication time for scheduling\n",
        "df['fecha'] = pd.to_datetime(df['timestamp']).dt.date\n",
        "hourly_counts = df.groupby([df['fecha'], df['timestamp'].dt.hour]).size().reset_index(name='tweet_count')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=hourly_counts, x='timestamp', y='tweet_count', estimator='mean') # Use mean to show average tweets per hour across days\n",
        "plt.title('Promedio de Tweets por Hora del D√≠a')\n",
        "plt.xlabel('Hora del D√≠a')\n",
        "plt.ylabel('Promedio de Tweets')\n",
        "plt.xticks(range(24))\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nAn√°lisis de la hora de publicaci√≥n:\")\n",
        "print(\"El gr√°fico de l√≠neas muestra el promedio de tweets publicados en cada hora del d√≠a.\")\n",
        "print(\"Los picos en este gr√°fico indican las horas en las que hay m√°s actividad de publicaci√≥n.\")\n",
        "print(\"Estas horas pico son los momentos √≥ptimos para programar tweets y alcanzar a la mayor audiencia posible.\")\n",
        "\n",
        "# Generate three tweets for the micro-campaign\n",
        "# Replace 'ChosenParty', 'DominantTopic', and tones as per your analysis\n",
        "party_for_campaign = 'Partido Ejemplo' # Replace with the party you chose for the campaign\n",
        "topic_for_campaign = 'Educaci√≥n y Juventud' # Replace with the dominant topic for that party\n",
        "\n",
        "tweet1_prompt = f\"Act√∫a como community manager del partido {party_for_campaign}. Crea un tweet de m√°x. 250 caracteres sobre el tema '{topic_for_campaign}'. Tono inspirador. No incluyas hashtags ni menciones.\"\n",
        "tweet2_prompt = f\"Act√∫a como community manager del partido {party_for_campaign}. Crea un tweet de m√°x. 250 caracteres sobre el tema '{topic_for_campaign}'. Tono informativo. No incluyas hashtags ni menciones.\"\n",
        "tweet3_prompt = f\"Act√∫a como community manager del partido {party_for_campaign}. Crea un tweet de m√°x. 250 caracteres sobre el tema '{topic_for_campaign}'. Tono de llamado a la acci√≥n. No incluyas hashtags ni menciones.\"\n",
        "\n",
        "# Ensure genai and model_fast are configured\n",
        "if 'model_fast' in globals():\n",
        "  tweet1 = generar_copy(model_fast, tweet1_prompt)\n",
        "  tweet2 = generar_copy(model_fast, tweet2_prompt)\n",
        "  tweet3 = generar_copy(model_fast, tweet3_prompt)\n",
        "\n",
        "  print(\"\\nTres tweets generados para la micro-campa√±a:\")\n",
        "  print(\"Tweet 1 (Tono inspirador):\")\n",
        "  print(tweet1)\n",
        "  print(\"\\nTweet 2 (Tono informativo):\")\n",
        "  print(tweet2)\n",
        "  print(\"\\nTweet 3 (Tono de llamado a la acci√≥n):\")\n",
        "  print(tweet3)\n",
        "else:\n",
        "  print(\"\\nGeneraci√≥n de tweets omitida: Aseg√∫rate de que el modelo genai 'model_fast' est√© configurado.\")\n",
        "\n",
        "\n",
        "# Write the Memo justifying the micro-campaign\n",
        "memo_content = f\"\"\"\n",
        "MEMO: Justificaci√≥n de Micro-campa√±a de Tweets\n",
        "\n",
        "Fecha: [Fecha Actual]\n",
        "Para: Equipo de Comunicaci√≥n Digital del {party_for_campaign}\n",
        "De: Analista de Marketing Digital\n",
        "Asunto: Propuesta de Micro-campa√±a en Twitter basada en An√°lisis de Datos\n",
        "\n",
        "Estimado equipo,\n",
        "\n",
        "Este memo justifica la implementaci√≥n de una micro-campa√±a estrat√©gica en Twitter para el {party_for_campaign}, fundamentada en un an√°lisis detallado de los datos de tweets recopilados.\n",
        "\n",
        "El an√°lisis de **sentimiento** revel√≥ que si bien hay una distribuci√≥n de opiniones, existe una oportunidad para capitalizar o contrarrestar ciertos climas emocionales. Hemos identificado el {partido_mas_conversacion} como el partido con mayor volumen de conversaci√≥n, lo que subraya la necesidad de tener una estrategia de comunicaci√≥n clara y efectiva para destacar en este espacio competitivo. Al monitorear el sentimiento en tiempo real durante la campa√±a, podremos ajustar nuestro mensaje si es necesario.\n",
        "\n",
        "El modelado de **temas** nos permiti√≥ identificar que '{topic_for_campaign}' es un tema dominante y de \"propiedad\" para nuestro partido, lo que significa que es un √°rea donde nuestra audiencia espera que tengamos una postura clara y propuestas s√≥lidas. Enfocarnos en este tema nos permite hablar directamente a los intereses principales de nuestros seguidores y diferenciar nuestro mensaje.\n",
        "\n",
        "La **segmentaci√≥n** de usuarios nos ha proporcionado una comprensi√≥n m√°s profunda de nuestra audiencia. Hemos identificado el Segmento (Cluster) {prioritized_cluster_id} como prioritario para la viralizaci√≥n debido a su alta actividad y tono a menudo participativo. Las acciones de engagement propuestas para cada segmento buscan adaptar nuestra interacci√≥n a sus comportamientos y expectativas, maximizando el impacto de cada tweet.\n",
        "\n",
        "En base a la hora de publicaci√≥n analizada, hemos determinado que los **horarios √≥ptimos** para programar nuestros tweets son [Mencionar las horas pico identificadas en el gr√°fico]. Publicar en estos momentos asegura que nuestro mensaje alcance a la mayor cantidad de usuarios activos en la plataforma.\n",
        "\n",
        "Los **tonos** elegidos para los tweets generados (inspirador, informativo, llamado a la acci√≥n) buscan abordar el tema '{topic_for_campaign}' desde diferentes √°ngulos para resonar con distintas sensibilidades dentro de nuestros segmentos. El tono inspirador busca conectar emocionalmente, el informativo busca educar y generar confianza, y el llamado a la acci√≥n busca movilizar a la audiencia.\n",
        "\n",
        "Como **KPI de √©xito** para esta micro-campa√±a, proponemos la m√©trica de **Tasa de Engagement (Engagement Rate)**, definida como (Likes + Retweets + Respuestas) / Impresiones. Nuestra **meta** es lograr una Tasa de Engagement del [Definir una meta num√©rica, ej. 1.5% o superior] para los tweets de la campa√±a, superando el promedio hist√≥rico de nuestros tweets.\n",
        "\n",
        "En resumen, esta micro-campa√±a est√° dise√±ada para ser altamente dirigida, utilizando los insights de sentimiento, temas y segmentos para optimizar el contenido, el tono y el horario de publicaci√≥n, con el objetivo claro de aumentar la interacci√≥n y la difusi√≥n de nuestro mensaje sobre '{topic_for_campaign}'.\n",
        "\n",
        "Atentamente,\n",
        "\n",
        "[Tu Nombre]\n",
        "Analista de Marketing Digital\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n--- MEMO ---\")\n",
        "print(memo_content)\n",
        "print(\"------------\")\n",
        "\n",
        "# Export notebook and memo (Manual step, as direct export from code is limited in Colab)\n",
        "print(\"\\nPara entrega:\")\n",
        "print(\"1. Guarda este notebook ejecutado (.ipynb file).\")\n",
        "print(\"2. Copia el contenido del MEMO impreso arriba y p√©galo en un documento de texto o PDF.\")\n",
        "print(\"3. Adjunta ambos archivos para la entrega.\")\n",
        "\n",
        "# Optional: Save memo to a file\n",
        "# try:\n",
        "#     with open(\"memo_microcampana.txt\", \"w\") as f:\n",
        "#         f.write(memo_content)\n",
        "#     print(\"\\nMemo guardado como 'memo_microcampana.txt'\")\n",
        "#     files.download('memo_microcampana.txt')\n",
        "# except Exception as e:\n",
        "#     print(f\"Error al guardar el memo en archivo: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "JrKQOI_qDDdp",
        "outputId": "6334a9cc-bd55-43aa-a76d-8207f2db0eda"
      },
      "id": "JrKQOI_qDDdp",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "An√°lisis de la hora de publicaci√≥n:\n",
            "El gr√°fico de l√≠neas muestra el promedio de tweets publicados en cada hora del d√≠a.\n",
            "Los picos en este gr√°fico indican las horas en las que hay m√°s actividad de publicaci√≥n.\n",
            "Estas horas pico son los momentos √≥ptimos para programar tweets y alcanzar a la mayor audiencia posible.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-ac293efd3e01>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Ensure genai and model_fast are configured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'model_fast'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mtweet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerar_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet1_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mtweet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerar_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet2_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mtweet3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerar_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet3_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-fe151967e40b>\u001b[0m in \u001b[0;36mgenerar_copy\u001b[0;34m(partido, topic, tono)\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0;34mf\"Crea un tweet de m√°x. 250 caracteres sobre el tema '{topic}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               f\"Tono {tono}. No incluyas hashtags ni menciones.\")\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}