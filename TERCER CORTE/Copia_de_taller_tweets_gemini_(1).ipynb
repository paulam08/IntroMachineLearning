{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b357f7b0",
      "metadata": {
        "id": "b357f7b0"
      },
      "source": [
        "# Taller: Análisis de Tweets con Gemini API\n",
        "Autor: _(Paula Maldonado)_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe82eab",
      "metadata": {
        "id": "2fe82eab"
      },
      "source": [
        "## Objetivos\n",
        "1. Configurar la API de Google Generative AI (Gemini).\n",
        "2. Limpiar y pre‑procesar un corpus de tweets políticos.\n",
        "3. Clasificar sentimiento con Gemini.\n",
        "4. Extraer temas con LDA y nombrarlos con Gemini.\n",
        "5. Segmentar usuarios y generar una micro‑campaña basada en insights.\n",
        "\n",
        "**Dataset**: `tweets_partidos.csv` (columnas: `cuenta`, `partido`, `timestamp`, `tweet`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/javierherrera1996/IntroMarketingAnalytics/raw/refs/heads/main/SegundoCorte/tweets_politica_kaggle.csv.zip"
      ],
      "metadata": {
        "id": "e8udN5R9O0km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e08fe5-ac70-4d5d-8b3f-4483b0d250ae"
      },
      "id": "e8udN5R9O0km",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-26 18:49:42--  https://github.com/javierherrera1996/IntroMarketingAnalytics/raw/refs/heads/main/SegundoCorte/tweets_politica_kaggle.csv.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/javierherrera1996/IntroMarketingAnalytics/refs/heads/main/SegundoCorte/tweets_politica_kaggle.csv.zip [following]\n",
            "--2025-05-26 18:49:42--  https://raw.githubusercontent.com/javierherrera1996/IntroMarketingAnalytics/refs/heads/main/SegundoCorte/tweets_politica_kaggle.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18276075 (17M) [application/zip]\n",
            "Saving to: ‘tweets_politica_kaggle.csv.zip’\n",
            "\n",
            "tweets_politica_kag 100%[===================>]  17.43M  92.6MB/s    in 0.2s    \n",
            "\n",
            "2025-05-26 18:49:43 (92.6 MB/s) - ‘tweets_politica_kaggle.csv.zip’ saved [18276075/18276075]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tweets_politica_kaggle.csv.zip"
      ],
      "metadata": {
        "id": "PJC93YJdO1vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2e5c0a-ded9-4b66-e4b3-289a06a6e648"
      },
      "id": "PJC93YJdO1vG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tweets_politica_kaggle.csv.zip\n",
            "  inflating: tweets_politica_kaggle.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('tweets_politica_kaggle.csv',delimiter=\",\",on_bad_lines='skip')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "LXleE-CzQZ0m",
        "outputId": "86a41859-8add-4261-8487-090c26e5abb6"
      },
      "id": "LXleE-CzQZ0m",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   cuenta\\tpartido\\ttimestamp\\ttweet\n",
              "0  a34133350b0605cb24081843f63176ca\\tpsoe\\t136397...\n",
              "1  a34133350b0605cb24081843f63176ca\\tpsoe\\t136406...\n",
              "2  a34133350b0605cb24081843f63176ca\\tpsoe\\t136411...\n",
              "3  a34133350b0605cb24081843f63176ca\\tpsoe\\t136415...\n",
              "4  a34133350b0605cb24081843f63176ca\\tpsoe\\t136415..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cfeee06-cc82-4fea-bcf5-d8fd2c076b97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cuenta\\tpartido\\ttimestamp\\ttweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136397...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136406...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136411...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136415...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a34133350b0605cb24081843f63176ca\\tpsoe\\t136415...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cfeee06-cc82-4fea-bcf5-d8fd2c076b97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cfeee06-cc82-4fea-bcf5-d8fd2c076b97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cfeee06-cc82-4fea-bcf5-d8fd2c076b97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68337c45-5a21-4a7f-bdaa-83fc972b4cef\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68337c45-5a21-4a7f-bdaa-83fc972b4cef')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68337c45-5a21-4a7f-bdaa-83fc972b4cef button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 81097,\n  \"fields\": [\n    {\n      \"column\": \"cuenta\\tpartido\\ttimestamp\\ttweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 80991,\n        \"samples\": [\n          \"1e826d8471835f7feb02f8028b736ebb\\tpp\\t1610190565.0\\tEnero de 2018\\ud83d\\udc49\\ud83c\\udffc S\\u00e1nchez denunciaba la gesti\\u00f3n de una nevada incomparable a la que ahora deja Filomena en Madrid.Enero de 2021\\ud83d\\udc49\\ud83c\\udffc S\\u00e1nchez no est\\u00e1 ni se le espera.\\ud83d\\udd34\\u00bfAhora no exige responsabilidades?\\ud83d\\udd34\\u00bfYa no pide explicaciones?\\ud83d\\udd34\\u00bfD\\u00f3nde est\\u00e1 escondido con la que est\\u00e1 cayendo? https://t.co/akRw8ljDnw\",\n          \"647360a97c0671126705c66ebdeacd33\\tpodemos\\t1644342435.0\\t\\\"\\ud83c\\udfa5 \\\"\\\"Tenemos un proyecto que pasa por garantizar todos los derechos de los ciudadanos y las ciudadanas de Castilla y Le\\u00f3n. Que Unidas Podemos est\\u00e9 fuerte es la mejor garant\\u00eda de que hay vidas dignas para los castellanos y los leoneses\\\"\\\".@IreneMontero en Valladolid \\ud83d\\udc47 https://t.co/qZk8FGFDXA\\\"\",\n          \"3a97e533064700b11a5679036006ab12\\tpsoe\\t1627465295.0\\t#QuoVadisEuropa @uimp El debate sobre la promoci\\u00f3n de valores y democracia desde la UE al resto del mundo.https://t.co/mwU5jTxsCF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bb91e5a2",
      "metadata": {
        "id": "bb91e5a2"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai nltk seaborn wordcloud scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906704c8",
      "metadata": {
        "id": "906704c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd15766",
      "metadata": {
        "id": "6dd15766"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e18f9a",
      "metadata": {
        "id": "b4e18f9a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4a8217c6",
      "metadata": {
        "id": "4a8217c6"
      },
      "source": [
        "### 🔍 Preguntas – Sección 1 (Exploración)\n",
        "1. **¿Cuántos tweets hay en total?**  \n",
        "2. **¿Qué partidos aparecen y cuántos tweets aporta cada uno?**  \n",
        "3. **¿Cuál es el rango de fechas cubierto por los tweets?**  \n",
        "4. **¿Qué partido genera más conversación y por qué crees que ocurre?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file, specifying the tab delimiter\n",
        "df = pd.read_csv('tweets_politica_kaggle.csv', delimiter='\\t', on_bad_lines='skip')\n",
        "\n",
        "# Now, accessing the 'partido' column should work\n",
        "partidos_counts = df['partido'].value_counts()\n",
        "print(\"\\nTweets por partido:\")\n",
        "print(partidos_counts)\n",
        "\n",
        "# Continue with the rest of the original code for calculations and printing\n",
        "total_tweets = len(df)\n",
        "print(f\"Total de tweets: {total_tweets}\")\n",
        "\n",
        "# Convert the 'timestamp' column to datetime objects\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "fecha_inicio = df['timestamp'].min()\n",
        "fecha_fin = df['timestamp'].max()\n",
        "print(f\"\\nRango de fechas: Desde {fecha_inicio} hasta {fecha_fin}\")\n",
        "\n",
        "# Determine the party with the most tweets\n",
        "partido_mas_conversacion = partidos_counts.idxmax()\n",
        "print(f\"\\nEl partido que genera más conversación es: {partido_mas_conversacion}\")\n",
        "print(\"Posibles razones (cualitativas, no derivadas del código):\")\n",
        "print(\"- Eventos políticos importantes que involucraron a ese partido.\")\n",
        "print(\"- Mayor número de seguidores activos en Twitter.\")\n",
        "print(\"- Estrategias de comunicación digital más efectivas por parte del partido.\")\n",
        "print(\"- Controversias o noticias relevantes relacionadas con el partido.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO_frfMG7wXq",
        "outputId": "30ddece0-1ff7-407d-999d-e3135637e51b"
      },
      "id": "FO_frfMG7wXq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tweets por partido:\n",
            "partido\n",
            "psoe          42818\n",
            "vox           38277\n",
            "pp            35059\n",
            "podemos       34442\n",
            "ciudadanos    30908\n",
            "Name: count, dtype: int64\n",
            "Total de tweets: 181504\n",
            "\n",
            "Rango de fechas: Desde 1970-01-01 00:00:01.363973492 hasta 1970-01-01 00:00:01.651224962\n",
            "\n",
            "El partido que genera más conversación es: psoe\n",
            "Posibles razones (cualitativas, no derivadas del código):\n",
            "- Eventos políticos importantes que involucraron a ese partido.\n",
            "- Mayor número de seguidores activos en Twitter.\n",
            "- Estrategias de comunicación digital más efectivas por parte del partido.\n",
            "- Controversias o noticias relevantes relacionadas con el partido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c06a3675",
      "metadata": {
        "id": "c06a3675"
      },
      "source": [
        "### 🧹 Preguntas – Sección 2 (Limpieza)\n",
        "5. Explica **por qué es importante limpiar y normalizar el texto**.  \n",
        "6. Enumera **tres tipos de “ruido”** que removes y da un ejemplo de cada uno."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es fundamental limpiar y normalizar el texto por varias razones, especialmente cuando se trabaja con datos como tweets. Los textos sin procesar suelen contener elementos que no aportan información útil para el análisis y pueden incluso distorsionar los resultados. Al limpiar y normalizar, nos aseguramos de que el texto esté en un formato consistente y relevante, lo que mejora la precisión y efectividad de las tareas posteriores como el análisis de sentimiento, la extracción de temas o la segmentación.\n",
        "\n",
        "Tres tipos de “ruido” que se suelen eliminar son:\n",
        "\n",
        "1.  **Caracteres especiales y signos de puntuación:** Estos elementos a menudo no tienen un significado lingüístico directo en el contexto de un análisis de contenido y pueden introducir ruido.\n",
        "    *   **Ejemplo:** Eliminar `!` , `?` , `@` , `#` , `,` , `.` de un tweet como `\"¡Hola @usuario! Este es un tweet #interesante...\"` lo dejaría como `\"Hola usuario Este es un tweet interesante\"`.\n",
        "\n",
        "2.  **URLs y menciones de usuario:** Las direcciones web y los nombres de usuario (`@`) son específicos de la plataforma (Twitter en este caso) y generalmente no contribuyen al contenido semántico del tweet.\n",
        "    *   **Ejemplo:** Eliminar `https://t.co/abcdef` y `@usuario` de `\"Mira este artículo: https://t.co/abcdef vía @usuario\"` lo dejaría como `\"Mira este artículo: vía\"`.\n",
        "\n",
        "3.  **Stop words (palabras vacías):** Son palabras muy comunes en un idioma (como \"el\", \"la\", \"y\", \"un\", \"una\") que no suelen aportar mucho significado distintivo al texto, especialmente para tareas como la identificación de temas.\n",
        "    *   **Ejemplo:** Eliminar \"el\", \"y\", \"la\" de `\"El perro y la casa son grandes\"` lo dejaría como `\"perro casa grandes\"`.\n",
        "    *   **Ejemplo:** Eliminar `!` , `?` , `@` , `#` , `,` , `.` de un tweet como `\"¡Hola @usuario! Este es un tweet #interesante...\"` lo dejaría como `\"Hola usuario Este es un tweet interesante\"`."
      ],
      "metadata": {
        "id": "8AekQFqw8Zpt"
      },
      "id": "8AekQFqw8Zpt"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vG9jACNQ8ZWd"
      },
      "id": "vG9jACNQ8ZWd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a2bdb175",
      "metadata": {
        "id": "a2bdb175"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Configure the API key (assuming you have set the GOOGLE_API_KEY environment variable)\n",
        "# Replace with your actual API key if not using environment variable\n",
        "# genai.configure(api_key='YOUR_API_KEY')\n",
        "\n",
        "# Define and initialize the model_fast variable\n",
        "# Using a fast model suitable for classification tasks\n",
        "model_fast = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "\n",
        "# Now, define the classify_sentiment function\n",
        "def classify_sentiment(text, model=model_fast):\n",
        "    prompt = (f\"Clasifica el sentimiento del siguiente tweet como 'positivo', \"\n",
        "              f\"'neutral' o 'negativo'. Solo responde con una palabra.\\n\\nTweet:\\n{text}\")\n",
        "    return model.generate_content(prompt).text.strip().lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bfbc892",
      "metadata": {
        "id": "0bfbc892"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "93d108b4",
      "metadata": {
        "id": "93d108b4"
      },
      "source": [
        "### 😊 Preguntas – Sección 3 (Sentimiento)\n",
        "7. Presenta la **distribución global** de sentimientos y comenta.  \n",
        "8. **¿Qué partido tiene la mayor proporción de tweets positivos y negativos?**  \n",
        "9. Elige un **pico de sentimiento negativo** y analiza el contexto con un tweet ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d542876c",
      "metadata": {
        "id": "d542876c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cecdef9-2947-4785-a98c-dd1b3029cfd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La columna 'sentimiento' no se encuentra en el DataFrame. Por favor, asegúrate de haber ejecutado la clasificación de sentimiento previamente.\n"
          ]
        }
      ],
      "source": [
        "# prompt: Presenta la distribución global de sentimientos y comenta.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' now has a 'sentimiento' column from the previous step\n",
        "if 'sentimiento' in df.columns:\n",
        "    # Get the distribution of sentiments\n",
        "    sentiment_counts = df['sentimiento'].value_counts(normalize=True) * 100\n",
        "\n",
        "    # Print the distribution\n",
        "    print(\"\\nDistribución Global de Sentimientos:\")\n",
        "    print(sentiment_counts)\n",
        "\n",
        "    # Plot the distribution\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)\n",
        "    plt.title('Distribución Global de Sentimientos en Tweets')\n",
        "    plt.xlabel('Sentimiento')\n",
        "    plt.ylabel('Porcentaje')\n",
        "    plt.show()\n",
        "\n",
        "    # Comment on the distribution\n",
        "    print(\"\\nComentario sobre la distribución de sentimientos:\")\n",
        "    print(\"Observamos la proporción de tweets clasificados como positivo, neutral y negativo a nivel global.\")\n",
        "    print(\"Este gráfico de barras muestra visualmente qué sentimiento predomina en el conjunto de datos total.\")\n",
        "    print(\"Podemos inferir, por ejemplo, si hay una tendencia general más positiva, negativa o neutral en la conversación política analizada.\")\n",
        "    print(\"Dependiendo de los resultados, esto podría indicar el clima general de opinión sobre los temas o actores políticos representados en los tweets.\")\n",
        "else:\n",
        "    # This block is executed if the 'sentimiento' column is not found\n",
        "    print(\"La columna 'sentimiento' no se encuentra en el DataFrame. Por favor, asegúrate de haber ejecutado la clasificación de sentimiento previamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "70882b31",
      "metadata": {
        "id": "70882b31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0fc390-e3e7-4297-f1ec-2127266f6598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Las columnas 'sentimiento' y/o 'partido' no se encuentran en el DataFrame. Por favor, asegúrate de haber ejecutado la clasificación de sentimiento y de que la columna 'partido' esté presente.\n"
          ]
        }
      ],
      "source": [
        "# prompt: Las columnas 'sentimiento' y/o 'partido' no se encuentran en el DataFrame. Por favor, asegúrate de haber ejecutado la clasificación de sentimiento y de que la columna 'partido' esté presente.\n",
        "\n",
        "# Check if both 'sentimiento' and 'partido' columns exist before proceeding\n",
        "if 'sentimiento' in df.columns and 'partido' in df.columns:\n",
        "    # Calculate the proportion of positive and negative tweets per party\n",
        "    sentiment_party = df.groupby('partido')['sentimiento'].value_counts(normalize=True).unstack()\n",
        "\n",
        "    # Identify the party with the highest proportion of positive tweets\n",
        "    if 'positivo' in sentiment_party.columns:\n",
        "        most_positive_party = sentiment_party['positivo'].idxmax()\n",
        "        print(f\"\\nPartido con la mayor proporción de tweets positivos: {most_positive_party}\")\n",
        "        print(f\"Proporción de tweets positivos para {most_positive_party}: {sentiment_party.loc[most_positive_party, 'positivo']:.2%}\")\n",
        "    else:\n",
        "        print(\"\\nNo hay tweets clasificados como 'positivo' en el DataFrame.\")\n",
        "\n",
        "    # Identify the party with the highest proportion of negative tweets\n",
        "    if 'negativo' in sentiment_party.columns:\n",
        "        most_negative_party = sentiment_party['negativo'].idxmax()\n",
        "        print(f\"Partido con la mayor proporción de tweets negativos: {most_negative_party}\")\n",
        "        print(f\"Proporción de tweets negativos para {most_negative_party}: {sentiment_party.loc[most_negative_party, 'negativo']:.2%}\")\n",
        "    else:\n",
        "         print(\"\\nNo hay tweets clasificados como 'negativo' en el DataFrame.\")\n",
        "\n",
        "else:\n",
        "    # This block is executed if either 'sentimiento' or 'partido' column is not found\n",
        "    print(\"Las columnas 'sentimiento' y/o 'partido' no se encuentran en el DataFrame. Por favor, asegúrate de haber ejecutado la clasificación de sentimiento y de que la columna 'partido' esté presente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Configure the API key (assuming you have set the GOOGLE_API_KEY environment variable)\n",
        "# Replace with your actual API key if not using environment variable\n",
        "genai.configure(api_key='YOUR_API_KEY') # <-- Uncomment this line and add your API key\n",
        "\n",
        "# Define and initialize the model_fast variable\n",
        "# Using a fast model suitable for classification tasks\n",
        "model_fast = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "\n",
        "# Now, define the classify_sentiment function\n",
        "def classify_sentiment(text, model=model_fast):\n",
        "    prompt = (f\"Clasifica el sentimiento del siguiente tweet como 'positivo', \"\n",
        "              f\"'neutral' o 'negativo'. Solo responde con una palabra.\\n\\nTweet:\\n{text}\")\n",
        "    return model.generate_content(prompt).text.strip().lower()"
      ],
      "metadata": {
        "id": "5QieZBZP9pE4"
      },
      "id": "5QieZBZP9pE4",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "38ebd1db",
      "metadata": {
        "id": "38ebd1db"
      },
      "source": [
        "### 🗂️ Preguntas – Sección 4 (Temas)\n",
        "10. Lista los **nombres de los temas** generados. ¿Alguno es inesperado?  \n",
        "11. Con un heatmap partido × tema, indica *qué tema es “propiedad”* de cada partido.  \n",
        "12. Para tu partido elegido, da **dos insights accionables** basados en su tema dominante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c270aaef",
      "metadata": {
        "id": "c270aaef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8741ea-b999-4748-9c1e-ee1e54d33d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombres de los temas generados:\n",
            "Tema 1: Educación y Juventud\n",
            "Tema 2: Economía y Empleo\n",
            "Tema 3: Salud y Bienestar\n",
            "Tema 4: Seguridad y Orden Público\n",
            "Tema 5: Política Exterior y Relaciones Internacionales\n",
            "\n",
            "Comentario sobre los nombres de los temas:\n",
            "Analiza la lista de nombres de temas. ¿Hay algún tema que no esperabas encontrar?\n",
            "Considera el contexto político y social del país al que pertenecen los tweets para evaluar si los temas identificados son coherentes o si hay sorpresas.\n",
            "Por ejemplo, un tema inesperado podría ser uno muy específico o uno que no se asocia comúnmente con el debate político.\n",
            "Las columnas 'partido' y/o 'topic' no se encuentran en el DataFrame. Asegúrate de haber realizado el modelado de temas (LDA) y haber asignado un tema dominante a cada tweet.\n",
            "El partido 'Partido Ejemplo' no se encontró en la columna 'partido' o las columnas 'partido'/'topic' no están disponibles.\n"
          ]
        }
      ],
      "source": [
        "# prompt: Lista los nombres de los temas generados. ¿Alguno es inesperado?\n",
        "# Con un heatmap partido × tema, indica qué tema es “propiedad” de cada partido.\n",
        "# Para tu partido elegido, da dos insights accionables basados en su tema dominante.\n",
        "\n",
        "# Assuming 'topic_names' is a list containing the names of the generated topics\n",
        "# This list should be populated from the previous LDA topic modeling step.\n",
        "# Example placeholder:\n",
        "topic_names = [\"Educación y Juventud\", \"Economía y Empleo\", \"Salud y Bienestar\", \"Seguridad y Orden Público\", \"Política Exterior y Relaciones Internacionales\"] # Replace with your actual topic names\n",
        "\n",
        "print(\"Nombres de los temas generados:\")\n",
        "for i, topic_name in enumerate(topic_names):\n",
        "    print(f\"Tema {i+1}: {topic_name}\")\n",
        "\n",
        "print(\"\\nComentario sobre los nombres de los temas:\")\n",
        "print(\"Analiza la lista de nombres de temas. ¿Hay algún tema que no esperabas encontrar?\")\n",
        "print(\"Considera el contexto político y social del país al que pertenecen los tweets para evaluar si los temas identificados son coherentes o si hay sorpresas.\")\n",
        "print(\"Por ejemplo, un tema inesperado podría ser uno muy específico o uno que no se asocia comúnmente con el debate político.\")\n",
        "\n",
        "# Assuming 'df' has a 'partido' column and 'topic' column (where 'topic' is the dominant topic index for each tweet)\n",
        "# This 'topic' column should be added after the LDA topic modeling step.\n",
        "# Create a cross-tabulation of party and dominant topic\n",
        "if 'partido' in df.columns and 'topic' in df.columns:\n",
        "    party_topic_counts = pd.crosstab(df['partido'], df['topic'])\n",
        "\n",
        "    # Normalize the counts to get proportions per party\n",
        "    party_topic_proportions = party_topic_counts.apply(lambda x: x / x.sum(), axis=1)\n",
        "\n",
        "    # Map topic indices to topic names for better readability\n",
        "    party_topic_proportions.columns = topic_names\n",
        "\n",
        "    # Plot the heatmap\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(party_topic_proportions, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
        "    plt.title('Proporción de Tweets por Tema y Partido')\n",
        "    plt.xlabel('Tema')\n",
        "    plt.ylabel('Partido')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nInterpretación del Heatmap:\")\n",
        "    print(\"El heatmap muestra la proporción de tweets de cada partido que se clasifican dentro de cada tema.\")\n",
        "    print(\"Los valores más altos (colores más oscuros) indican que un tema es más 'propiedad' o más frecuentemente discutido por un partido en particular.\")\n",
        "    print(\"Esto ayuda a identificar qué temas son prioritarios para cada plataforma política.\")\n",
        "\n",
        "else:\n",
        "    print(\"Las columnas 'partido' y/o 'topic' no se encuentran en el DataFrame. Asegúrate de haber realizado el modelado de temas (LDA) y haber asignado un tema dominante a cada tweet.\")\n",
        "\n",
        "\n",
        "# --- Insight accionable para un partido elegido ---\n",
        "\n",
        "# Choose a party to analyze\n",
        "# Replace 'Partido Ejemplo' with the actual name of a party from your dataset\n",
        "chosen_party = 'Partido Ejemplo' #@param {type:\"string\"}\n",
        "\n",
        "if 'partido' in df.columns and 'topic' in df.columns and chosen_party in df['partido'].unique():\n",
        "    # Find the dominant topic for the chosen party\n",
        "    if chosen_party in party_topic_proportions.index:\n",
        "        dominant_topic_index = party_topic_proportions.loc[chosen_party].idxmax()\n",
        "        dominant_topic_name = dominant_topic_index # It's already the name due to re-indexing\n",
        "\n",
        "        print(f\"\\nAnálisis para el partido: {chosen_party}\")\n",
        "        print(f\"Tema dominante: {dominant_topic_name}\")\n",
        "\n",
        "        print(\"\\nDos insights accionables basados en el tema dominante:\")\n",
        "        # Insight 1: Focus on the dominant theme in communication\n",
        "        print(f\"1. Aumentar la comunicación y las propuestas relacionadas con '{dominant_topic_name}'.\")\n",
        "        print(f\"   Dado que este tema resuena más con la audiencia del partido o es un área de fortaleza, enfocarse en él puede mejorar el engagement y la percepción pública.\")\n",
        "        print(f\"   Acción: Crear más contenido (tweets, videos, comunicados) que aborde específicamente asuntos de '{dominant_topic_name}', destacando las soluciones y logros del partido en esta área.\")\n",
        "\n",
        "        # Insight 2: Identify sub-topics or specific issues within the dominant theme\n",
        "        # This would require drilling down into the tweets related to the dominant topic for the chosen party\n",
        "        # For this example, we'll provide a general insight\n",
        "        print(f\"2. Analizar sub-temas o preocupaciones específicas dentro de '{dominant_topic_name}' que generen mayor interacción.\")\n",
        "        print(f\"   Dentro de un tema amplio como '{dominant_topic_name}', puede haber aspectos particulares que interesen más a los seguidores o generen más debate.\")\n",
        "        print(f\"   Acción: Examinar los tweets de '{chosen_party}' clasificados en '{dominant_topic_name}' para identificar palabras clave o frases recurrentes que indiquen sub-temas específicos. Luego, diseñar campañas de comunicación que aborden directamente estas inquietudes particulares.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"El partido '{chosen_party}' no se encontró en los datos de proporciones de temas.\")\n",
        "\n",
        "else:\n",
        "    print(f\"El partido '{chosen_party}' no se encontró en la columna 'partido' o las columnas 'partido'/'topic' no están disponibles.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d2fe739",
      "metadata": {
        "id": "0d2fe739"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c2d37f48",
      "metadata": {
        "id": "c2d37f48"
      },
      "source": [
        "### 👥 Preguntas – Sección 5 (Segmentación)\n",
        "13. Describe cada **cluster** en una frase (actividad y tono).  \n",
        "14. **¿Qué segmento priorizarías** para viralizar un mensaje y por qué?  \n",
        "15. Propón **una acción de engagement** distinta para cada segmento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b52da84a",
      "metadata": {
        "id": "b52da84a"
      },
      "outputs": [],
      "source": [
        "def generar_copy(partido, topic, tono='inspirador'):\n",
        "    prompt = (f\"Actúa como community manager del partido {partido}. \"\n",
        "              f\"Crea un tweet de máx. 250 caracteres sobre el tema '{topic}'. \"\n",
        "              f\"Tono {tono}. No incluyas hashtags ni menciones.\")\n",
        "    return model.generate_content(prompt).text.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75a38277",
      "metadata": {
        "id": "75a38277"
      },
      "source": [
        "### 📝 Preguntas – Sección 6 (Micro‑campaña)\n",
        "16. Presenta tus **tres tweets** generados.  \n",
        "17. Justifica:  \n",
        "   a) **Tema** elegido.  \n",
        "   b) **Tono** y **horario** óptimos.  \n",
        "18. Define un **KPI de éxito** y la meta para la campaña."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    # Ensure the model object is available within the function\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    # Ensure the model object is available within the function\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "def generar_copy(model, prompt):\n",
        "    \"\"\"\n",
        "    Generates text content using the provided generative model and prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The generative model object to use (e.g., a Google AI model).\n",
        "        prompt (str): The prompt to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text content, with leading/trailing whitespace removed.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "hxQdxszy-DdK",
        "outputId": "322a9544-1aba-4023-d471-d5c200161486"
      },
      "id": "hxQdxszy-DdK",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-104-b47d7eee3afb>, line 48)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-104-b47d7eee3afb>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    Generates text content using the provided generative model and prompt.\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2565b39a",
      "metadata": {
        "id": "2565b39a"
      },
      "source": [
        "## Próximos pasos\n",
        "1. Analiza la hora de publicación (`df['fecha'].dt.hour`) para programar los tweets.\n",
        "2. Escribe un memo (<400 palabras) justificando la micro‑campaña usando los insights de sentimiento, temas y segmentos.\n",
        "3. Exporta notebook ejecutado y memo para entrega."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Analiza la hora de publicación (df['fecha'].dt.hour) para programar los tweets.\n",
        "# Escribe un memo (<400 palabras) justificando la micro‑campaña usando los insights de sentimiento, temas y segmentos.\n",
        "# Exporta notebook ejecutado y memo para entrega.\n",
        "\n",
        "# Analyze publication time for scheduling\n",
        "df['fecha'] = pd.to_datetime(df['timestamp']).dt.date\n",
        "hourly_counts = df.groupby([df['fecha'], df['timestamp'].dt.hour]).size().reset_index(name='tweet_count')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=hourly_counts, x='timestamp', y='tweet_count', estimator='mean') # Use mean to show average tweets per hour across days\n",
        "plt.title('Promedio de Tweets por Hora del Día')\n",
        "plt.xlabel('Hora del Día')\n",
        "plt.ylabel('Promedio de Tweets')\n",
        "plt.xticks(range(24))\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nAnálisis de la hora de publicación:\")\n",
        "print(\"El gráfico de líneas muestra el promedio de tweets publicados en cada hora del día.\")\n",
        "print(\"Los picos en este gráfico indican las horas en las que hay más actividad de publicación.\")\n",
        "print(\"Estas horas pico son los momentos óptimos para programar tweets y alcanzar a la mayor audiencia posible.\")\n",
        "\n",
        "# Generate three tweets for the micro-campaign\n",
        "# Replace 'ChosenParty', 'DominantTopic', and tones as per your analysis\n",
        "party_for_campaign = 'Partido Ejemplo' # Replace with the party you chose for the campaign\n",
        "topic_for_campaign = 'Educación y Juventud' # Replace with the dominant topic for that party\n",
        "\n",
        "tweet1_prompt = f\"Actúa como community manager del partido {party_for_campaign}. Crea un tweet de máx. 250 caracteres sobre el tema '{topic_for_campaign}'. Tono inspirador. No incluyas hashtags ni menciones.\"\n",
        "tweet2_prompt = f\"Actúa como community manager del partido {party_for_campaign}. Crea un tweet de máx. 250 caracteres sobre el tema '{topic_for_campaign}'. Tono informativo. No incluyas hashtags ni menciones.\"\n",
        "tweet3_prompt = f\"Actúa como community manager del partido {party_for_campaign}. Crea un tweet de máx. 250 caracteres sobre el tema '{topic_for_campaign}'. Tono de llamado a la acción. No incluyas hashtags ni menciones.\"\n",
        "\n",
        "# Ensure genai and model_fast are configured\n",
        "if 'model_fast' in globals():\n",
        "  tweet1 = generar_copy(model_fast, tweet1_prompt)\n",
        "  tweet2 = generar_copy(model_fast, tweet2_prompt)\n",
        "  tweet3 = generar_copy(model_fast, tweet3_prompt)\n",
        "\n",
        "  print(\"\\nTres tweets generados para la micro-campaña:\")\n",
        "  print(\"Tweet 1 (Tono inspirador):\")\n",
        "  print(tweet1)\n",
        "  print(\"\\nTweet 2 (Tono informativo):\")\n",
        "  print(tweet2)\n",
        "  print(\"\\nTweet 3 (Tono de llamado a la acción):\")\n",
        "  print(tweet3)\n",
        "else:\n",
        "  print(\"\\nGeneración de tweets omitida: Asegúrate de que el modelo genai 'model_fast' esté configurado.\")\n",
        "\n",
        "\n",
        "# Write the Memo justifying the micro-campaign\n",
        "memo_content = f\"\"\"\n",
        "MEMO: Justificación de Micro-campaña de Tweets\n",
        "\n",
        "Fecha: [Fecha Actual]\n",
        "Para: Equipo de Comunicación Digital del {party_for_campaign}\n",
        "De: Analista de Marketing Digital\n",
        "Asunto: Propuesta de Micro-campaña en Twitter basada en Análisis de Datos\n",
        "\n",
        "Estimado equipo,\n",
        "\n",
        "Este memo justifica la implementación de una micro-campaña estratégica en Twitter para el {party_for_campaign}, fundamentada en un análisis detallado de los datos de tweets recopilados.\n",
        "\n",
        "El análisis de **sentimiento** reveló que si bien hay una distribución de opiniones, existe una oportunidad para capitalizar o contrarrestar ciertos climas emocionales. Hemos identificado el {partido_mas_conversacion} como el partido con mayor volumen de conversación, lo que subraya la necesidad de tener una estrategia de comunicación clara y efectiva para destacar en este espacio competitivo. Al monitorear el sentimiento en tiempo real durante la campaña, podremos ajustar nuestro mensaje si es necesario.\n",
        "\n",
        "El modelado de **temas** nos permitió identificar que '{topic_for_campaign}' es un tema dominante y de \"propiedad\" para nuestro partido, lo que significa que es un área donde nuestra audiencia espera que tengamos una postura clara y propuestas sólidas. Enfocarnos en este tema nos permite hablar directamente a los intereses principales de nuestros seguidores y diferenciar nuestro mensaje.\n",
        "\n",
        "La **segmentación** de usuarios nos ha proporcionado una comprensión más profunda de nuestra audiencia. Hemos identificado el Segmento (Cluster) {prioritized_cluster_id} como prioritario para la viralización debido a su alta actividad y tono a menudo participativo. Las acciones de engagement propuestas para cada segmento buscan adaptar nuestra interacción a sus comportamientos y expectativas, maximizando el impacto de cada tweet.\n",
        "\n",
        "En base a la hora de publicación analizada, hemos determinado que los **horarios óptimos** para programar nuestros tweets son [Mencionar las horas pico identificadas en el gráfico]. Publicar en estos momentos asegura que nuestro mensaje alcance a la mayor cantidad de usuarios activos en la plataforma.\n",
        "\n",
        "Los **tonos** elegidos para los tweets generados (inspirador, informativo, llamado a la acción) buscan abordar el tema '{topic_for_campaign}' desde diferentes ángulos para resonar con distintas sensibilidades dentro de nuestros segmentos. El tono inspirador busca conectar emocionalmente, el informativo busca educar y generar confianza, y el llamado a la acción busca movilizar a la audiencia.\n",
        "\n",
        "Como **KPI de éxito** para esta micro-campaña, proponemos la métrica de **Tasa de Engagement (Engagement Rate)**, definida como (Likes + Retweets + Respuestas) / Impresiones. Nuestra **meta** es lograr una Tasa de Engagement del [Definir una meta numérica, ej. 1.5% o superior] para los tweets de la campaña, superando el promedio histórico de nuestros tweets.\n",
        "\n",
        "En resumen, esta micro-campaña está diseñada para ser altamente dirigida, utilizando los insights de sentimiento, temas y segmentos para optimizar el contenido, el tono y el horario de publicación, con el objetivo claro de aumentar la interacción y la difusión de nuestro mensaje sobre '{topic_for_campaign}'.\n",
        "\n",
        "Atentamente,\n",
        "\n",
        "[Tu Nombre]\n",
        "Analista de Marketing Digital\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n--- MEMO ---\")\n",
        "print(memo_content)\n",
        "print(\"------------\")\n",
        "\n",
        "# Export notebook and memo (Manual step, as direct export from code is limited in Colab)\n",
        "print(\"\\nPara entrega:\")\n",
        "print(\"1. Guarda este notebook ejecutado (.ipynb file).\")\n",
        "print(\"2. Copia el contenido del MEMO impreso arriba y pégalo en un documento de texto o PDF.\")\n",
        "print(\"3. Adjunta ambos archivos para la entrega.\")\n",
        "\n",
        "# Optional: Save memo to a file\n",
        "# try:\n",
        "#     with open(\"memo_microcampana.txt\", \"w\") as f:\n",
        "#         f.write(memo_content)\n",
        "#     print(\"\\nMemo guardado como 'memo_microcampana.txt'\")\n",
        "#     files.download('memo_microcampana.txt')\n",
        "# except Exception as e:\n",
        "#     print(f\"Error al guardar el memo en archivo: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "JrKQOI_qDDdp",
        "outputId": "6334a9cc-bd55-43aa-a76d-8207f2db0eda"
      },
      "id": "JrKQOI_qDDdp",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Análisis de la hora de publicación:\n",
            "El gráfico de líneas muestra el promedio de tweets publicados en cada hora del día.\n",
            "Los picos en este gráfico indican las horas en las que hay más actividad de publicación.\n",
            "Estas horas pico son los momentos óptimos para programar tweets y alcanzar a la mayor audiencia posible.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-ac293efd3e01>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Ensure genai and model_fast are configured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'model_fast'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mtweet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerar_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet1_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mtweet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerar_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet2_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mtweet3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerar_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet3_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-fe151967e40b>\u001b[0m in \u001b[0;36mgenerar_copy\u001b[0;34m(partido, topic, tono)\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0;34mf\"Crea un tweet de máx. 250 caracteres sobre el tema '{topic}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               f\"Tono {tono}. No incluyas hashtags ni menciones.\")\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}